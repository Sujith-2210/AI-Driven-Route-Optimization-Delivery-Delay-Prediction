{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI-Driven Delivery Delay Prediction\n",
                "\n",
                "This notebook covers:\n",
                "1. **Data Preparation** - Load LaDe dataset, calculate & simulate features\n",
                "2. **Exploratory Data Analysis** - Visualize patterns and correlations\n",
                "3. **Model Training** - Random Forest, XGBoost, Gradient Boosting\n",
                "4. **Model Evaluation & Selection** - Compare and save best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install pandas numpy scikit-learn xgboost matplotlib seaborn -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime, timedelta\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Data Preparation\n",
                "\n",
                "### 1.1 Load Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load LaDe dataset from local sample file\n",
                "# (Downloaded from Hugging Face: Cainiao-AI/LaDe-D - Shanghai delivery data)\n",
                "print(\"Loading LaDe Shanghai dataset from local file...\")\n",
                "df_lade = pd.read_csv('Datasets/lade_shanghai_sample.csv')\n",
                "\n",
                "print(f\"Loaded {len(df_lade)} records from LaDe dataset\")\n",
                "print(f\"Columns: {list(df_lade.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display sample data\n",
                "print(\"Sample data from LaDe dataset:\")\n",
                "df_lade.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load existing Delivery_Logistics dataset for feature distributions\n",
                "df_logistics = pd.read_csv('Datasets/Delivery_Logistics.csv')\n",
                "print(f\"Loaded Delivery_Logistics.csv: {len(df_logistics)} records\")\n",
                "print(f\"Columns: {list(df_logistics.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Calculate Distance from GPS Coordinates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from math import radians, cos, sin, asin, sqrt\n",
                "\n",
                "def haversine(lon1, lat1, lon2, lat2):\n",
                "    \"\"\"Calculate the great circle distance in km between two points on earth.\"\"\"\n",
                "    # Convert to radians\n",
                "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
                "    \n",
                "    # Haversine formula\n",
                "    dlon = lon2 - lon1\n",
                "    dlat = lat2 - lat1\n",
                "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
                "    c = 2 * asin(sqrt(a))\n",
                "    r = 6371  # Radius of earth in km\n",
                "    return c * r\n",
                "\n",
                "# Calculate distance\n",
                "df_lade['distance_km'] = df_lade.apply(\n",
                "    lambda row: haversine(\n",
                "        row['accept_gps_lng'], row['accept_gps_lat'],\n",
                "        row['lng'], row['lat']\n",
                "    ), axis=1\n",
                ")\n",
                "\n",
                "print(\"Distance statistics (km):\")\n",
                "print(df_lade['distance_km'].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Parse and Process Timestamps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parse timestamps (format: MM-DD HH:MM:SS)\n",
                "# We'll assume year 2024 for all dates\n",
                "\n",
                "def parse_lade_time(time_str):\n",
                "    \"\"\"Parse LaDe timestamp format (MM-DD HH:MM:SS) to datetime.\"\"\"\n",
                "    try:\n",
                "        # Format: '06-04 11:05:00'\n",
                "        return datetime.strptime(f\"2024-{time_str}\", \"%Y-%m-%d %H:%M:%S\")\n",
                "    except:\n",
                "        return None\n",
                "\n",
                "# Parse order time (accept_time) and actual delivery time\n",
                "df_lade['order_time'] = df_lade['accept_time'].apply(parse_lade_time)\n",
                "df_lade['actual_delivery_time'] = df_lade['delivery_time'].apply(parse_lade_time)\n",
                "\n",
                "# Remove rows with invalid timestamps\n",
                "df_lade = df_lade.dropna(subset=['order_time', 'actual_delivery_time'])\n",
                "\n",
                "# Calculate actual delivery duration in hours\n",
                "df_lade['delivery_duration_hours'] = (df_lade['actual_delivery_time'] - df_lade['order_time']).dt.total_seconds() / 3600\n",
                "\n",
                "# Filter out negative or unrealistic durations (> 24 hours)\n",
                "df_lade = df_lade[(df_lade['delivery_duration_hours'] > 0) & (df_lade['delivery_duration_hours'] <= 24)]\n",
                "\n",
                "print(f\"Records after timestamp filtering: {len(df_lade)}\")\n",
                "print(\"\\nDelivery duration statistics (hours):\")\n",
                "print(df_lade['delivery_duration_hours'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate scheduled delivery time based on distance\n",
                "# Assumption: Average speed of 15 km/h in urban areas + 30 min buffer\n",
                "\n",
                "def estimate_delivery_time(distance_km):\n",
                "    \"\"\"Estimate delivery time in hours based on distance.\"\"\"\n",
                "    avg_speed = 15  # km/h (considering traffic, stops, etc.)\n",
                "    buffer_hours = 0.5  # 30 minutes buffer for pickup/dropoff\n",
                "    return (distance_km / avg_speed) + buffer_hours\n",
                "\n",
                "df_lade['expected_duration_hours'] = df_lade['distance_km'].apply(estimate_delivery_time)\n",
                "df_lade['scheduled_delivery_time'] = df_lade['order_time'] + pd.to_timedelta(df_lade['expected_duration_hours'], unit='h')\n",
                "\n",
                "# Create target variable: delayed (1 if actual > scheduled)\n",
                "df_lade['delayed'] = (df_lade['actual_delivery_time'] > df_lade['scheduled_delivery_time']).astype(int)\n",
                "\n",
                "print(f\"\\nDelay distribution:\")\n",
                "print(df_lade['delayed'].value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.4 Simulate Missing Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get distributions from Delivery_Logistics.csv\n",
                "vehicle_types = df_logistics['vehicle_type'].value_counts(normalize=True).to_dict()\n",
                "weather_conditions = df_logistics['weather_condition'].value_counts(normalize=True).to_dict()\n",
                "\n",
                "print(\"Vehicle type distribution:\")\n",
                "print(vehicle_types)\n",
                "print(\"\\nWeather condition distribution:\")\n",
                "print(weather_conditions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n = len(df_lade)\n",
                "\n",
                "# 1. Vehicle Type - based on distribution from Delivery_Logistics\n",
                "vehicle_list = list(vehicle_types.keys())\n",
                "vehicle_probs = list(vehicle_types.values())\n",
                "df_lade['vehicle_type'] = np.random.choice(vehicle_list, size=n, p=vehicle_probs)\n",
                "\n",
                "# 2. Package Weight - simulate using distribution from Delivery_Logistics\n",
                "weight_mean = df_logistics['package_weight_kg'].mean()\n",
                "weight_std = df_logistics['package_weight_kg'].std()\n",
                "df_lade['package_weight_kg'] = np.abs(np.random.normal(weight_mean, weight_std, n))\n",
                "\n",
                "# 3. Weather Conditions - based on distribution\n",
                "weather_list = list(weather_conditions.keys())\n",
                "weather_probs = list(weather_conditions.values())\n",
                "df_lade['weather_condition'] = np.random.choice(weather_list, size=n, p=weather_probs)\n",
                "\n",
                "# 4. Traffic Level - based on hour of order\n",
                "def get_traffic_level(hour):\n",
                "    if hour in [7, 8, 17, 18]:\n",
                "        return 'Very High'\n",
                "    elif hour in [9, 10, 15, 16]:\n",
                "        return 'High'\n",
                "    elif hour in [11, 12, 13, 14]:\n",
                "        return 'Medium'\n",
                "    else:\n",
                "        return 'Low'\n",
                "\n",
                "df_lade['order_hour'] = df_lade['order_time'].dt.hour\n",
                "df_lade['traffic_level'] = df_lade['order_hour'].apply(get_traffic_level)\n",
                "\n",
                "# 5. Road Type - based on distance\n",
                "def get_road_type(distance):\n",
                "    if distance < 3:\n",
                "        return 'City'\n",
                "    elif distance < 15:\n",
                "        return 'Highway'\n",
                "    else:\n",
                "        return 'Rural'\n",
                "\n",
                "df_lade['road_type'] = df_lade['distance_km'].apply(get_road_type)\n",
                "\n",
                "print(\"Simulated features added!\")\n",
                "print(f\"\\nVehicle types: {df_lade['vehicle_type'].value_counts().to_dict()}\")\n",
                "print(f\"\\nTraffic levels: {df_lade['traffic_level'].value_counts().to_dict()}\")\n",
                "print(f\"\\nRoad types: {df_lade['road_type'].value_counts().to_dict()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.5 Create Final Dataset with All Required Columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the final prepared dataset with all required columns\n",
                "df_final = df_lade[[\n",
                "    'order_id',              # Delivery ID\n",
                "    'accept_gps_lat',        # Source latitude\n",
                "    'accept_gps_lng',        # Source longitude\n",
                "    'lat',                   # Destination latitude\n",
                "    'lng',                   # Destination longitude\n",
                "    'distance_km',           # Distance\n",
                "    'vehicle_type',          # Vehicle type\n",
                "    'courier_id',            # Driver ID\n",
                "    'package_weight_kg',     # Package weight\n",
                "    'order_time',            # Order time\n",
                "    'scheduled_delivery_time', # Scheduled delivery time\n",
                "    'actual_delivery_time',  # Actual delivery time\n",
                "    'traffic_level',         # Traffic level\n",
                "    'weather_condition',     # Weather conditions\n",
                "    'road_type',             # Road type\n",
                "    'delayed'                # Target variable\n",
                "]].copy()\n",
                "\n",
                "# Rename columns for clarity\n",
                "df_final.columns = [\n",
                "    'delivery_id', 'source_lat', 'source_lng', 'dest_lat', 'dest_lng',\n",
                "    'distance_km', 'vehicle_type', 'driver_id', 'package_weight_kg',\n",
                "    'order_time', 'scheduled_delivery_time', 'actual_delivery_time',\n",
                "    'traffic_level', 'weather_condition', 'road_type', 'delayed'\n",
                "]\n",
                "\n",
                "print(f\"Final dataset shape: {df_final.shape}\")\n",
                "print(f\"\\nColumns: {list(df_final.columns)}\")\n",
                "df_final.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "print(\"Missing values:\")\n",
                "print(df_final.isnull().sum())\n",
                "\n",
                "# Data types\n",
                "print(\"\\nData types:\")\n",
                "print(df_final.dtypes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the prepared dataset\n",
                "df_final.to_csv('prepared_logistics_dataset.csv', index=False)\n",
                "print(\"Dataset saved to 'prepared_logistics_dataset.csv'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 2: Exploratory Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset overview\n",
                "print(\"=\" * 50)\n",
                "print(\"DATASET OVERVIEW\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\nTotal records: {len(df_final):,}\")\n",
                "print(f\"Total features: {len(df_final.columns)}\")\n",
                "print(f\"\\nTarget variable distribution:\")\n",
                "print(df_final['delayed'].value_counts())\n",
                "print(f\"\\nDelay rate: {df_final['delayed'].mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "df_final.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizations\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "# 1. Delay distribution\n",
                "ax1 = axes[0, 0]\n",
                "df_final['delayed'].value_counts().plot(kind='bar', ax=ax1, color=['green', 'red'])\n",
                "ax1.set_title('Delay Distribution')\n",
                "ax1.set_xlabel('Delayed')\n",
                "ax1.set_ylabel('Count')\n",
                "ax1.set_xticklabels(['On Time', 'Delayed'], rotation=0)\n",
                "\n",
                "# 2. Distance distribution\n",
                "ax2 = axes[0, 1]\n",
                "df_final['distance_km'].hist(bins=50, ax=ax2, color='steelblue', edgecolor='black')\n",
                "ax2.set_title('Distance Distribution')\n",
                "ax2.set_xlabel('Distance (km)')\n",
                "ax2.set_ylabel('Frequency')\n",
                "\n",
                "# 3. Vehicle type vs Delay\n",
                "ax3 = axes[0, 2]\n",
                "delay_by_vehicle = df_final.groupby('vehicle_type')['delayed'].mean()\n",
                "delay_by_vehicle.plot(kind='bar', ax=ax3, color='coral')\n",
                "ax3.set_title('Delay Rate by Vehicle Type')\n",
                "ax3.set_xlabel('Vehicle Type')\n",
                "ax3.set_ylabel('Delay Rate')\n",
                "ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45)\n",
                "\n",
                "# 4. Traffic level vs Delay\n",
                "ax4 = axes[1, 0]\n",
                "delay_by_traffic = df_final.groupby('traffic_level')['delayed'].mean()\n",
                "delay_by_traffic.reindex(['Low', 'Medium', 'High', 'Very High']).plot(kind='bar', ax=ax4, color='purple')\n",
                "ax4.set_title('Delay Rate by Traffic Level')\n",
                "ax4.set_xlabel('Traffic Level')\n",
                "ax4.set_ylabel('Delay Rate')\n",
                "ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45)\n",
                "\n",
                "# 5. Weather vs Delay\n",
                "ax5 = axes[1, 1]\n",
                "delay_by_weather = df_final.groupby('weather_condition')['delayed'].mean()\n",
                "delay_by_weather.plot(kind='bar', ax=ax5, color='teal')\n",
                "ax5.set_title('Delay Rate by Weather')\n",
                "ax5.set_xlabel('Weather Condition')\n",
                "ax5.set_ylabel('Delay Rate')\n",
                "ax5.set_xticklabels(ax5.get_xticklabels(), rotation=45)\n",
                "\n",
                "# 6. Road type vs Delay\n",
                "ax6 = axes[1, 2]\n",
                "delay_by_road = df_final.groupby('road_type')['delayed'].mean()\n",
                "delay_by_road.reindex(['City', 'Highway', 'Rural']).plot(kind='bar', ax=ax6, color='orange')\n",
                "ax6.set_title('Delay Rate by Road Type')\n",
                "ax6.set_xlabel('Road Type')\n",
                "ax6.set_ylabel('Delay Rate')\n",
                "ax6.set_xticklabels(ax6.get_xticklabels(), rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('eda_visualizations.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation heatmap for numerical features\n",
                "numerical_cols = ['source_lat', 'source_lng', 'dest_lat', 'dest_lng', \n",
                "                  'distance_km', 'package_weight_kg', 'delayed']\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "correlation_matrix = df_final[numerical_cols].corr()\n",
                "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
                "            square=True, linewidths=0.5, fmt='.2f')\n",
                "plt.title('Correlation Heatmap')\n",
                "plt.tight_layout()\n",
                "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 3: Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, roc_auc_score, classification_report,\n",
                "    roc_curve\n",
                ")\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "print(\"Model training libraries imported!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features for modeling\n",
                "feature_cols = ['distance_km', 'package_weight_kg', 'vehicle_type', \n",
                "                'traffic_level', 'weather_condition', 'road_type']\n",
                "\n",
                "# Create a copy for modeling\n",
                "df_model = df_final[feature_cols + ['delayed']].copy()\n",
                "\n",
                "# Encode categorical variables\n",
                "label_encoders = {}\n",
                "categorical_cols = ['vehicle_type', 'traffic_level', 'weather_condition', 'road_type']\n",
                "\n",
                "for col in categorical_cols:\n",
                "    le = LabelEncoder()\n",
                "    df_model[col] = le.fit_transform(df_model[col])\n",
                "    label_encoders[col] = le\n",
                "\n",
                "print(\"Features encoded!\")\n",
                "df_model.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data\n",
                "X = df_model.drop('delayed', axis=1)\n",
                "y = df_model['delayed']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training set: {len(X_train)} samples\")\n",
                "print(f\"Test set: {len(X_test)} samples\")\n",
                "print(f\"\\nClass distribution in training set:\")\n",
                "print(y_train.value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define models\n",
                "models = {\n",
                "    'Random Forest': RandomForestClassifier(\n",
                "        n_estimators=100, \n",
                "        max_depth=10, \n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    ),\n",
                "    'XGBoost': XGBClassifier(\n",
                "        n_estimators=100, \n",
                "        max_depth=6, \n",
                "        learning_rate=0.1,\n",
                "        random_state=42,\n",
                "        eval_metric='logloss'\n",
                "    ),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(\n",
                "        n_estimators=100, \n",
                "        max_depth=5, \n",
                "        learning_rate=0.1,\n",
                "        random_state=42\n",
                "    )\n",
                "}\n",
                "\n",
                "print(\"Models defined:\")\n",
                "for name in models:\n",
                "    print(f\"  - {name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train and evaluate all models\n",
                "results = []\n",
                "trained_models = {}\n",
                "\n",
                "print(\"Training models...\\n\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"\\n{'='*20} {name} {'='*20}\")\n",
                "    \n",
                "    # Train\n",
                "    model.fit(X_train, y_train)\n",
                "    trained_models[name] = model\n",
                "    \n",
                "    # Predict\n",
                "    y_pred = model.predict(X_test)\n",
                "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    precision = precision_score(y_test, y_pred)\n",
                "    recall = recall_score(y_test, y_pred)\n",
                "    f1 = f1_score(y_test, y_pred)\n",
                "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "    \n",
                "    # Store results\n",
                "    results.append({\n",
                "        'Model': name,\n",
                "        'Accuracy': accuracy,\n",
                "        'Precision': precision,\n",
                "        'Recall': recall,\n",
                "        'F1 Score': f1,\n",
                "        'ROC-AUC': roc_auc\n",
                "    })\n",
                "    \n",
                "    # Print metrics\n",
                "    print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
                "    print(f\"Precision: {precision:.4f}\")\n",
                "    print(f\"Recall:    {recall:.4f}\")\n",
                "    print(f\"F1 Score:  {f1:.4f}\")\n",
                "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
                "    \n",
                "    # Confusion Matrix\n",
                "    print(f\"\\nConfusion Matrix:\")\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    print(cm)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Results comparison\n",
                "results_df = pd.DataFrame(results)\n",
                "results_df = results_df.set_index('Model')\n",
                "print(\"\\nMODEL COMPARISON:\")\n",
                "print(\"=\" * 70)\n",
                "print(results_df.round(4))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize model comparison\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Bar chart of metrics\n",
                "ax1 = axes[0]\n",
                "results_df[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']].plot(\n",
                "    kind='bar', ax=ax1, width=0.8\n",
                ")\n",
                "ax1.set_title('Model Performance Comparison')\n",
                "ax1.set_ylabel('Score')\n",
                "ax1.set_ylim(0, 1)\n",
                "ax1.legend(loc='lower right')\n",
                "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
                "\n",
                "# ROC Curves\n",
                "ax2 = axes[1]\n",
                "for name, model in trained_models.items():\n",
                "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
                "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
                "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "    ax2.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
                "\n",
                "ax2.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
                "ax2.set_xlabel('False Positive Rate')\n",
                "ax2.set_ylabel('True Positive Rate')\n",
                "ax2.set_title('ROC Curves')\n",
                "ax2.legend(loc='lower right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance for best model\n",
                "best_model_name = results_df['ROC-AUC'].idxmax()\n",
                "best_model = trained_models[best_model_name]\n",
                "\n",
                "print(f\"\\nBest Model: {best_model_name}\")\n",
                "print(f\"ROC-AUC: {results_df.loc[best_model_name, 'ROC-AUC']:.4f}\")\n",
                "\n",
                "# Get feature importance\n",
                "if hasattr(best_model, 'feature_importances_'):\n",
                "    importance = pd.DataFrame({\n",
                "        'Feature': X.columns,\n",
                "        'Importance': best_model.feature_importances_\n",
                "    }).sort_values('Importance', ascending=True)\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.barh(importance['Feature'], importance['Importance'], color='steelblue')\n",
                "    plt.xlabel('Importance')\n",
                "    plt.title(f'Feature Importance - {best_model_name}')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 4: Save Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create models directory\n",
                "os.makedirs('models', exist_ok=True)\n",
                "\n",
                "# Save the best model\n",
                "model_path = 'models/best_delay_prediction_model.pkl'\n",
                "joblib.dump(best_model, model_path)\n",
                "print(f\"Best model ({best_model_name}) saved to: {model_path}\")\n",
                "\n",
                "# Save label encoders for inference\n",
                "encoders_path = 'models/label_encoders.pkl'\n",
                "joblib.dump(label_encoders, encoders_path)\n",
                "print(f\"Label encoders saved to: {encoders_path}\")\n",
                "\n",
                "# Save model comparison results\n",
                "results_df.to_csv('models/model_comparison_results.csv')\n",
                "print(f\"Model comparison results saved to: models/model_comparison_results.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test loading and prediction\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"TESTING SAVED MODEL\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Load model\n",
                "loaded_model = joblib.load(model_path)\n",
                "loaded_encoders = joblib.load(encoders_path)\n",
                "\n",
                "# Sample prediction\n",
                "sample = X_test.iloc[0:1]\n",
                "prediction = loaded_model.predict(sample)\n",
                "probability = loaded_model.predict_proba(sample)[0]\n",
                "\n",
                "print(f\"\\nSample features: {sample.values[0]}\")\n",
                "print(f\"Prediction: {'Delayed' if prediction[0] == 1 else 'On Time'}\")\n",
                "print(f\"Probability: On Time={probability[0]:.2%}, Delayed={probability[1]:.2%}\")\n",
                "print(f\"Actual: {'Delayed' if y_test.iloc[0] == 1 else 'On Time'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "### Dataset\n",
                "- **Source**: LaDe-D (Hugging Face) + Delivery_Logistics.csv\n",
                "- **Records**: 5,000 deliveries from Shanghai\n",
                "- **Features**: 16 columns including GPS, timestamps, vehicle, weather, traffic\n",
                "\n",
                "### Models Trained\n",
                "1. Random Forest Classifier\n",
                "2. XGBoost Classifier\n",
                "3. Gradient Boosting Classifier\n",
                "\n",
                "### Outputs\n",
                "- `prepared_logistics_dataset.csv` - Final dataset\n",
                "- `models/best_delay_prediction_model.pkl` - Best trained model\n",
                "- `models/label_encoders.pkl` - Encoders for inference\n",
                "- `models/model_comparison_results.csv` - Performance metrics"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}